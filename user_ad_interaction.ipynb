{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda, Dropout, Concatenate, MultiHeadAttention, Layer, LayerNormalization, GlobalAveragePooling1D\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from IPython.display import display, Image, HTML, update_display\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import L1L2\n",
    "from threading import Thread, Lock\n",
    "import keras.backend as K\n",
    "import keras_tuner as kt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import warnings\n",
    "import datetime\n",
    "import dataset\n",
    "import tools\n",
    "import users\n",
    "import time\n",
    "import uuid\n",
    "import ads\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_directories = [\"ADS16_Benchmark_part1\", \"ADS16_Benchmark_part2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_user_and_ad_ftrs(root_directories, try_load_files=True, save_files=True):\n",
    "    ad_ftrs_path = os.path.join(\"data\", \"ad_ftrs.npz\")\n",
    "    user_ftrs_and_ratings_path = os.path.join(\"data\", \"user_ftrs_and_ratings.npz\")\n",
    "\n",
    "    if try_load_files and os.path.exists(ad_ftrs_path):\n",
    "        with np.load(ad_ftrs_path) as ad_ftrs_file:\n",
    "            ad_ftrs = (ad_ftrs_file[\"ftrs1\"], ad_ftrs_file[\"ftrs2\"])\n",
    "            num_categories = int(ad_ftrs_file[\"num_categories\"])\n",
    "    else:\n",
    "        ad_ftrs, num_categories = ads.load_ftrs(root_directories)\n",
    "        if save_files:\n",
    "            np.savez(ad_ftrs_path, ftrs1=ad_ftrs[0], ftrs2=ad_ftrs[1], num_categories=num_categories)\n",
    "    \n",
    "    if try_load_files and os.path.exists(user_ftrs_and_ratings_path):\n",
    "        with np.load(user_ftrs_and_ratings_path) as user_ftrs_and_ratings:\n",
    "            user_ftrs = user_ftrs_and_ratings[\"user_ftrs\"]\n",
    "            ratings = user_ftrs_and_ratings[\"ratings\"]\n",
    "    else:\n",
    "        raw_user_ftrs, ratings = users.load_raw_ftrs(root_directories)\n",
    "        *_, user_ftrs = users.calculate_pca_ftrs(raw_user_ftrs)\n",
    "        if save_files:\n",
    "            np.savez(user_ftrs_and_ratings_path, user_ftrs=user_ftrs, ratings=ratings)\n",
    "    \n",
    "    return ad_ftrs, num_categories, user_ftrs, ratings\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ad_ftrs, num_categories, user_ftrs, ratings = load_user_and_ad_ftrs(root_directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_ad_ftr_product(user_ftrs, ad_ftrs):\n",
    "    return (tools.ftr_cartesian_product(user_ftrs, ad_ftrs[0]), tools.ftr_cartesian_product(user_ftrs, ad_ftrs[1])[-1])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X = get_user_ad_ftr_product(user_ftrs, ad_ftrs)\n",
    "    Y = tools.to_one_hot(ratings.flatten(), 1, 5)\n",
    "    \n",
    "    test_split = 0.2\n",
    "    train_num = int((1-test_split) * X[0].shape[0])\n",
    "    X_train, X_test = tools.split_all(X, train_num)\n",
    "    Y_train, Y_test = Y[:train_num], Y[train_num:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distributions(model, title):\n",
    "    rows = num_categories + 1\n",
    "    cols = 3\n",
    "\n",
    "    fig = plt.figure(constrained_layout=True, figsize=(cols*8, rows*6))\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        fig.suptitle(title, fontsize=20)\n",
    "        fig.patch.set_facecolor(\"white\")\n",
    "        \n",
    "        subfigs = fig.subfigures(rows, 1)\n",
    "\n",
    "        pred = tools.from_one_hot(model.predict(X), 1, 5, mix=False).numpy()\n",
    "\n",
    "        user_ftr_params = users.approximate_normal_params(user_ftrs.T)\n",
    "        sim_user_ftrs = users.generate_synthetic_pca_ftrs(user_ftrs.shape[0], user_ftr_params)\n",
    "        \n",
    "        sim_pred = tools.from_one_hot(model.predict(get_user_ad_ftr_product(sim_user_ftrs, ad_ftrs)), 1, 5, mix=False).numpy()\n",
    "\n",
    "        subfig = subfigs[0]\n",
    "        subfig.suptitle(\"Overall Distributions\")\n",
    "        axs = subfig.subplots(1,3)\n",
    "        \n",
    "        pred_t = pred\n",
    "        sim_pred_t = sim_pred\n",
    "        # pred_t = np.clip(pred, 1, 5)\n",
    "        # sim_pred_t = np.clip(sim_pred, 1, 5).astype(int)\n",
    "        pred_t = np.round(pred_t).astype(int)\n",
    "        sim_pred_t = np.round(sim_pred_t).astype(int)\n",
    "\n",
    "        real_options = np.arange(1,6)\n",
    "        pred_options = np.arange(min(real_options[0], np.min(pred_t)), max(real_options[-1], np.max(pred_t))+1)\n",
    "        sim_pred_options = np.arange(min(real_options[0], np.min(sim_pred_t)), max(real_options[-1], np.max(sim_pred_t))+1)\n",
    "\n",
    "        real_sizes = np.array([np.sum(ratings == i) for i in real_options])\n",
    "        pred_sizes = np.array([np.sum(pred_t == i) for i in pred_options])\n",
    "        sim_pred_sizes = np.array([np.sum(sim_pred_t == i) for i in sim_pred_options])\n",
    "\n",
    "        i = 0\n",
    "        axs[i].set_title(\"Ground Truth\")\n",
    "        axs[i].pie(real_sizes, labels=real_options, autopct='%1.1f%%', counterclock=False, startangle=90, explode=[0.01]*len(real_sizes))\n",
    "        axs[i].legend()\n",
    "        i += 1\n",
    "\n",
    "        axs[i].set_title(\"Predicted (Real Users)\")\n",
    "        axs[i].pie(pred_sizes, labels=pred_options, autopct='%1.1f%%', counterclock=False, startangle=90, explode=[0.01]*len(pred_sizes))\n",
    "        axs[i].legend()\n",
    "        i += 1\n",
    "\n",
    "        axs[i].set_title(\"Predicted (Simulated Users)\")\n",
    "        axs[i].pie(sim_pred_sizes, labels=sim_pred_options, autopct='%1.1f%%', counterclock=False, startangle=90, explode=[0.01]*len(sim_pred_sizes))\n",
    "        axs[i].legend()\n",
    "        i += 1\n",
    "\n",
    "\n",
    "        for cat, subfig in enumerate(subfigs[1:]):\n",
    "            subfig.suptitle(f\"Category {cat}\", fontsize=16)\n",
    "\n",
    "            axs = subfig.subplots(1, cols)\n",
    "\n",
    "            for col, ax in enumerate(axs):\n",
    "                ax.plot()\n",
    "                ax.set_xlabel(f\"Rating\")\n",
    "                ax.set_ylabel(f\"Probability Density\")\n",
    "                ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "            cat_mask = ad_ftrs[0][:,cat] == 1\n",
    "            real_cat_ratings = ratings[:,cat_mask]\n",
    "            pred_cat_ratings = pred.reshape(ratings.shape)[:,cat_mask]\n",
    "            sim_cat_ratings = sim_pred.reshape(ratings.shape)[:,cat_mask]\n",
    "\n",
    "            def get_bins(x):\n",
    "                bins = np.arange(np.floor(min(np.min(x), np.min(real_cat_ratings))),np.ceil(max(np.max(x), np.max(real_cat_ratings)))+2,1) - 0.5\n",
    "                bin_centers = 0.5*(bins[1:]+bins[:-1])\n",
    "                return bins, bin_centers\n",
    "\n",
    "            real_bins, real_bin_centers = get_bins(real_cat_ratings)\n",
    "            pred_bins, pred_bin_centers = get_bins(pred_cat_ratings)\n",
    "            sim_bins, sim_bin_centers = get_bins(sim_cat_ratings)\n",
    "\n",
    "            i = 0\n",
    "\n",
    "            axs[i].set_title(f\"Ground Truth\")\n",
    "            for user in real_cat_ratings:\n",
    "                heights, _ = np.histogram(user, bins=real_bins, density=True)\n",
    "                axs[i].plot(real_bin_centers, heights, c=\"blue\", alpha=0.1)\n",
    "            i += 1\n",
    "            \n",
    "            axs[i].set_title(f\"Predicted (Real Users)\")\n",
    "            for user in pred_cat_ratings:\n",
    "                heights, _ = np.histogram(user, bins=pred_bins, density=True)\n",
    "                axs[i].plot(pred_bin_centers, heights, c=\"red\", alpha=0.1)\n",
    "            i += 1\n",
    "            \n",
    "            axs[i].set_title(f\"Predicted (Simulated Users)\")\n",
    "            for user in sim_cat_ratings:\n",
    "                heights, _ = np.histogram(user, bins=sim_bins, density=True)\n",
    "                axs[i].plot(sim_bin_centers, heights, c=\"green\", alpha=0.1)\n",
    "            i += 1\n",
    "        \n",
    "        plt.close()\n",
    "    return fig\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     display(plot_distributions(create_model(), \"Rating Distributions\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_with_args_kwargs(func, args, kwargs):\n",
    "    return func(*args, **kwargs)\n",
    "\n",
    "class DisplayableCallback(Callback):\n",
    "    def __init__(self, name, create_display_immediately=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.name = name\n",
    "        self.display_id = f\"{self.name}-{str(uuid.uuid1())}\"\n",
    "        if create_display_immediately:\n",
    "            self.create_display()\n",
    "    \n",
    "    def create_display(self):\n",
    "        display(HTML(self.name), display_id=self.display_id)\n",
    "    \n",
    "    def update_display(self, obj):\n",
    "        update_display(obj, display_id=self.display_id)\n",
    "\n",
    "class Printer(DisplayableCallback):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(\"Epoch Data\", **kwargs)\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        header = f\"Epoch {epoch}\"\n",
    "        lines = []\n",
    "        if logs is not None:\n",
    "            for k, v in logs.items():\n",
    "                lines.append(f\"{k}={v:.5f}\")\n",
    "        self.update_display(HTML(f\"<h3>{header}</h3>\"+\"<br/>\".join(lines)))\n",
    "        return super().on_epoch_end(epoch, logs=logs)\n",
    "    \n",
    "\n",
    "class ModelDisplayer(DisplayableCallback):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(\"Model Topology\", **kwargs)\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        model_plot_filename = \"data/tmp.png\"\n",
    "        plot_model(self.model, to_file=model_plot_filename, show_shapes=True, show_layer_activations=True, show_layer_names=True)\n",
    "        self.update_display(Image(model_plot_filename))\n",
    "        os.unlink(model_plot_filename)\n",
    "        return super().on_epoch_end(epoch, logs=logs)\n",
    "\n",
    "\n",
    "class DistributionPlotter(DisplayableCallback):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(\"Rating Distributions\", **kwargs)\n",
    "        self.lock = Lock()\n",
    "        \n",
    "    def on_epoch_end_(self, epoch, logs=None):\n",
    "        with self.lock:\n",
    "            self.update_display(plot_distributions(self.model, f\"Rating Distributions: Epoch {epoch}\"))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if not self.lock.locked():\n",
    "            Thread(target=self.on_epoch_end_, args=(epoch, logs)).start()\n",
    "        return super().on_epoch_end(epoch, logs=logs)\n",
    "    \n",
    "    def plot_now(self):\n",
    "        with self.lock:\n",
    "            self.update_display(plot_distributions(self.model, f\"Rating Distributions\"))\n",
    "            \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logs_dir=\"user_ad_interaction_model_logs\"\n",
    "    checkpoints_dir = os.path.join(logs_dir, \"checkpoints\")\n",
    "    filepath = os.path.join(checkpoints_dir, \"model-{epoch:06d}-{val_loss:06f}.hdf5\")\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor=[\"val_loss\"], save_weights_only=True, verbose=0, save_best_only=False, mode=\"min\")\n",
    "\n",
    "    log_dir = os.path.join(logs_dir, \"fit\", datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_mae(y_true, y_pred):\n",
    "    r_true = tools.from_one_hot(y_true, 1, 5, mix=False)\n",
    "    r_pred = tools.from_one_hot(y_pred, 1, 5, mix=False)\n",
    "    return tf.keras.metrics.mean_absolute_error(r_true, r_pred)\n",
    "\n",
    "def mixed_rating_mae(y_true, y_pred):\n",
    "    r_true = tools.from_one_hot(y_true, 1, 5, mix=True)\n",
    "    r_pred = tools.from_one_hot(y_pred, 1, 5, mix=True)\n",
    "    return tf.keras.metrics.mean_absolute_error(r_true, r_pred)\n",
    "\n",
    "\n",
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = Sequential(\n",
    "            [Dense(ff_dim, activation=\"relu\"), Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "\n",
    "def create_model(hp=None):\n",
    "    ad_ftrs, _, user_ftrs, ratings = load_user_and_ad_ftrs(root_directories)\n",
    "\n",
    "    inputs_1 = Input((user_ftrs.shape[1]+ad_ftrs[0].shape[1]), name=\"flat_input\")\n",
    "    inputs_2 = Input((ad_ftrs[1].shape[1:]), name=\"text_input\")\n",
    "\n",
    "    input_dropout_rate = 0.5 if hp is None else hp.Choice(\"input_dropout\", values=[0.0, 0.1, 0.3, 0.5])\n",
    "    subnet_1 = inputs_1 if input_dropout_rate == 0 else Dropout(input_dropout_rate, name=\"flat_input_dropout\")(inputs_1)\n",
    "    subnet_2 = inputs_2 if input_dropout_rate == 0 else Dropout(input_dropout_rate, name=\"text_input_dropout\")(inputs_2)\n",
    "\n",
    "    l1 = 1e-2 if hp is None else hp.Choice(\"l1\", values=[1e-2, 1e-3, 1e-4])\n",
    "    l2 = 1e-2 if hp is None else hp.Choice(\"l2\", values=[1e-2, 1e-3, 1e-4])\n",
    "    reg = L1L2(l1=l1, l2=l2)\n",
    "\n",
    "    num_hidden_layers = 2 if hp is None else hp.Int(\"num_hidden_layers\", 1, 3)\n",
    "    for i in range(num_hidden_layers):\n",
    "        units = 32 if hp is None else hp.Int(f\"units_{i}\", min_value=32, max_value=128, step=32)\n",
    "        subnet_1 = Dense(units, activation=\"relu\", kernel_regularizer=reg, name=f\"hidden_{i}\")(subnet_1)\n",
    "        dropout_rate = 0.5 if hp is None else hp.Choice(f\"dropout_{i}\", values=[0.0, 0.1, 0.3, 0.5])\n",
    "        if dropout_rate != 0:\n",
    "            subnet_1 = Dropout(dropout_rate, name=f\"hidden_dropout_{i}\")(subnet_1)\n",
    "\n",
    "    num_heads = 2 if hp is None else hp.Int(\"num_attn_heads\", min_value=1, max_value=8, step=1)\n",
    "    ff_dim = 32 if hp is None else hp.Int(\"ff_dim\", min_value=32, max_value=128, step=32)\n",
    "    dropout_rate = 0.5 if hp is None else hp.Choice(\"transformer_dropout_1\", values=[0.0, 0.1, 0.3, 0.5])\n",
    "    subnet_2 = TransformerBlock(embed_dim=ad_ftrs[1].shape[-1], num_heads=num_heads, ff_dim=ff_dim, rate=dropout_rate)(subnet_2)\n",
    "    subnet_2 = GlobalAveragePooling1D()(subnet_2)\n",
    "    dropout_rate = 0.5 if hp is None else hp.Choice(\"transformer_dropout_2\", values=[0.0, 0.1, 0.3, 0.5])\n",
    "    if dropout_rate != 0:\n",
    "        subnet_2 = Dropout(dropout_rate)(subnet_2)\n",
    "\n",
    "    output = Concatenate(name=\"combined_subnets\")([subnet_1, subnet_2])\n",
    "    units_final = 32 if hp is None else hp.Int(\"units_final\", min_value=32, max_value=128, step=32)\n",
    "    output = Dense(units_final, kernel_regularizer=reg, name=\"hidden_final\", activation=\"relu\")(output)\n",
    "    dropout_rate = 0.5 if hp is None else hp.Choice(\"dropout_final\", values=[0.0, 0.1, 0.3, 0.5])\n",
    "    if dropout_rate != 0:\n",
    "        output = Dropout(dropout_rate)(output)\n",
    "    output = Dense(5, kernel_regularizer=reg, name=\"output\", activation=\"softmax\")(output)\n",
    "\n",
    "    model = Model(inputs=[inputs_1, inputs_2], outputs=[output])\n",
    "    learning_rate = 1e-2 if hp is None else hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\", rating_mae, mixed_rating_mae]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "class MyTuner(kt.Hyperband):\n",
    "    def run_trial(self, trial, *args, **kwargs):\n",
    "        kwargs['batch_size'] = trial.hyperparameters.Int('batch_size', 32, 256, step=32)\n",
    "        return super().run_trial(trial, *args, **kwargs)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    tuner = MyTuner(\n",
    "            create_model,\n",
    "            objective=kt.Objective(\"val_rating_mae\", direction=\"min\"),\n",
    "            max_epochs=100,\n",
    "            factor=3,\n",
    "            hyperband_iterations=5,\n",
    "            directory=os.path.join(logs_dir, \"hypertraining\"),\n",
    "            project_name=\"user_ad_interaction\"\n",
    "        )\n",
    "    \n",
    "    # print(\"EXAMPLE MODEL --- HYPERPARAMS NOT TUNED\")\n",
    "    # model = create_model()\n",
    "    # model.summary()\n",
    "    # c = ModelDisplayer()\n",
    "    # c.model = model\n",
    "    # c.on_epoch_end(0)\n",
    "\n",
    "    # c = DistributionPlotter()\n",
    "    # c.model = model\n",
    "    # c.plot_now()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    epochs = 100\n",
    "    \n",
    "    if not os.path.isdir(checkpoints_dir):\n",
    "        os.makedirs(checkpoints_dir)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "        params = {\n",
    "            \"verbose\": 0,\n",
    "            \"shuffle\": True,\n",
    "            \"epochs\": epochs\n",
    "        }\n",
    "\n",
    "\n",
    "        display(HTML(\"<h2>HyperTuning</h2>\"))\n",
    "        tuner.search(\n",
    "            X_train,\n",
    "            Y_train,\n",
    "            **params,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[tensorboard_callback, Printer(), ModelDisplayer(), EarlyStopping(monitor='val_loss', mode=\"min\", patience=5)]\n",
    "        )\n",
    "\n",
    "\n",
    "        display(HTML(\"<h2>Found Optimal Model!</h2>\"))\n",
    "        num_trials = 1\n",
    "\n",
    "        tuner.results_summary(num_trials=num_trials)\n",
    "        print(\"\\n\")\n",
    "        best_hps=tuner.get_best_hyperparameters(num_trials=num_trials)[0]\n",
    "\n",
    "        model = tuner.hypermodel.build(best_hps)\n",
    "        batch_size = best_hps.Int('batch_size', 32, 256, step=32)\n",
    "        \n",
    "        # model = create_model()\n",
    "        # batch_size = 32\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            Y_train,\n",
    "            **params,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_test,Y_test),\n",
    "            callbacks=[tensorboard_callback, checkpoint, ModelDisplayer(), Printer(), d:=DistributionPlotter()]#, EarlyStopping(monitor='val_loss', mode=\"min\", patience=5)]\n",
    "        )\n",
    "\n",
    "        d.plot_now()\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe9152bf2f574327d6e225fe0caf6c004889fb08c66ba1e27720217847b14197"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

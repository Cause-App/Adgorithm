{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset from https://www.kaggle.com/datasets/groffo/ads16-dataset\n",
    "\n",
    "[1] Roffo, G., & Vinciarelli, A. (2016, August). Personality in computational advertising: A benchmark. In 4 th Workshop on Emotions and Personality in Personalized Systems (EMPIRE) 2016 (p. 18)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv3D, MaxPooling3D, Dense, Lambda, Flatten, Concatenate, LSTM, SimpleRNN\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from pandas import read_csv\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import datetime\n",
    "import string\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mpl.rcParams[\"figure.figsize\"] = (20, 6)\n",
    "\n",
    "    %load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ad_and_user_directories(root_directories):\n",
    "    ad_directories = []\n",
    "    user_directories = []\n",
    "\n",
    "    for directory in root_directories:\n",
    "        ad_directories_parent = os.path.join(directory, directory, \"Ads\", \"Ads\")\n",
    "        user_directories_parent = os.path.join(directory, directory, \"Corpus\", \"Corpus\")\n",
    "\n",
    "        ad_directories += list(os.path.join(ad_directories_parent, x) for x in os.listdir(ad_directories_parent))\n",
    "        user_directories += list(os.path.join(user_directories_parent, x) for x in os.listdir(user_directories_parent))\n",
    "\n",
    "    ad_directories = sorted(ad_directories, key=lambda x: int(x.replace(\"/\", \"\\\\\").split(\"\\\\\")[-1]))\n",
    "    user_directories = sorted(user_directories, key=lambda x: int(x.replace(\"/\", \"\\\\\").split(\"\\\\\")[-1][1:]))\n",
    "\n",
    "    num_categories = len(ad_directories)\n",
    "    return ad_directories, user_directories, num_categories\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ad_directories, user_directories, num_categories = get_ad_and_user_directories([\"ADS16_Benchmark_part1\", \"ADS16_Benchmark_part2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 16\n",
    "img_height = 16\n",
    "img_channels = 3\n",
    "\n",
    "def load_image(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    if img is None:\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        ret, img = cap.read()\n",
    "        cap.release()\n",
    "        assert ret\n",
    "    if img.shape[2] > 3:\n",
    "        y,x = img[:,:,3].nonzero()\n",
    "        assert y.shape[0] > 0 and x.shape[0] > 0\n",
    "        minx = np.min(x)\n",
    "        miny = np.min(y)\n",
    "        maxx = np.max(x)\n",
    "        maxy = np.max(y) \n",
    "        img = img[miny:maxy, minx:maxx, :img_channels]\n",
    "    img = cv2.resize(img, (img_width, img_height))\n",
    "    assert img.shape == (img_width, img_height, img_channels)\n",
    "    return img.astype(float) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ad category 20/20\n",
      "Embedding text...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "def load_ads(ad_directories, num_categories):\n",
    "    ad_categories = np.zeros((0, num_categories))\n",
    "    ad_imgs = np.zeros((0, img_width, img_height, img_channels))\n",
    "    ad_text = []\n",
    "    allowed_chars = list(string.ascii_lowercase + string.digits + \" .\")\n",
    "    char_embedding_size = len(allowed_chars)+1\n",
    "\n",
    "    last_ad_directory_id = ad_directories[-1].replace(\"/\", \"\\\\\").split(\"\\\\\")[-1]\n",
    "    for ad_directory in ad_directories:\n",
    "        ad_directory_id = ad_directory.replace(\"/\", \"\\\\\").split(\"\\\\\")[-1]\n",
    "        img_paths = list(os.path.join(ad_directory, x) for x in os.listdir(ad_directory))\n",
    "        categories = np.zeros((len(img_paths), num_categories))\n",
    "        categories[:,int(ad_directory.replace(\"/\", \"\\\\\").split(\"\\\\\")[-1])-1] = 1\n",
    "        img_arrays = np.array(list(map(load_image, img_paths)))\n",
    "        ad_categories = np.concatenate((ad_categories, categories))\n",
    "        ad_imgs = np.concatenate((img_arrays, ad_imgs))\n",
    "        ad_text += list(list(allowed_chars.index(x) if x in allowed_chars else len(allowed_chars) for x in i.lower()) for i in map(pytesseract.image_to_string, img_paths))\n",
    "        print(f\"Loaded ad category {ad_directory_id}/{last_ad_directory_id}\", end=\"\\r\")\n",
    "\n",
    "    print(\"\\nEmbedding text...\")\n",
    "\n",
    "    num_ads = ad_imgs.shape[0]\n",
    "    assert len(ad_text) == num_ads\n",
    "    max_text_length = max(map(len, ad_text))\n",
    "    ad_char_embeddings = np.zeros((num_ads, max_text_length, char_embedding_size))\n",
    "    for i, txt in enumerate(ad_text):\n",
    "        for j, c in enumerate(txt):\n",
    "            ad_char_embeddings[i, j, c] = 1\n",
    "        \n",
    "    print(\"Done\")\n",
    "\n",
    "    return ad_categories, ad_imgs, ad_char_embeddings, num_ads, char_embedding_size, max_text_length\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ad_categories, ad_imgs, ad_char_embeddings, num_ads, char_embedding_size, max_text_length = load_ads(ad_directories, num_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_data_iterator(user_directories):\n",
    "    failures = 0\n",
    "    for user_directory in user_directories:\n",
    "        user_id = user_directory.replace(\"/\", \"\\\\\").split(\"\\\\\")[-1]\n",
    "        b5 = read_csv(os.path.join(user_directory, f\"{user_id}-B5.csv\"), delimiter=\";\")[\"Answer\"].values\n",
    "        im_neg = read_csv(os.path.join(user_directory, f\"{user_id}-IM-NEG.csv\"), delimiter=\";\")\n",
    "        im_neg_paths = list(os.path.join(user_directory, f\"{user_id}-IM-NEG\", *x.replace(\"/\", \"\\\\\").split(\"\\\\\")[1:]) for x in im_neg.iloc[0].values)[:5]\n",
    "\n",
    "\n",
    "        im_pos = read_csv(os.path.join(user_directory, f\"{user_id}-IM-POS.csv\"), delimiter=\";\")\n",
    "        im_pos_paths = list(os.path.join(user_directory, f\"{user_id}-IM-POS\", *x.replace(\"/\", \"\\\\\").split(\"\\\\\")[1:]) for x in im_pos.iloc[0].values)[:5]\n",
    "        if len(im_neg_paths) != 5 or len(im_pos_paths) != 5:\n",
    "            failures += 1\n",
    "            print(f\"Failed to load user {user_id} (not enough images): {failures} total failure{'' if failures == 1 else 's'}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            im_neg_arrays = np.array(list(map(load_image, im_neg_paths)))\n",
    "            im_pos_arrays = np.array(list(map(load_image, im_pos_paths)))\n",
    "        except AssertionError:\n",
    "            failures += 1\n",
    "            print(f\"Failed to load user {user_id} (bad images): {failures} total failure{'' if failures == 1 else 's'}\")\n",
    "            continue\n",
    "\n",
    "        # im_neg_labels = im_neg.iloc[1].values\n",
    "        # im_pos_labels = im_pos.iloc[1].values\n",
    "\n",
    "        inf = read_csv(os.path.join(user_directory, f\"{user_id}-INF.csv\"), delimiter=\";\")\n",
    "        gender_age_income = np.array([[1 if x[0] == \"F\" else 0 if x[0] == \"M\" else 0.5, *x[1:]] for x in inf[[\"Gender\", \"Age\", \"Income\"]].values][0])\n",
    "        \n",
    "        rt = read_csv(os.path.join(user_directory, f\"{user_id}-RT.csv\"), delimiter=\";\")\n",
    "        mean_rt_per_cat = np.mean(np.array(list(list(int(i) for i in x.split(\",\")) for x in rt.iloc[1].values)), axis=1)\n",
    "        ratings = np.array(list(map(int, \",\".join(rt.iloc[1].values).split(\",\"))))\n",
    "        ratings_one_hot = np.eye(5)[ratings-1]\n",
    "\n",
    "        yield (user_id, b5, im_neg_arrays, im_pos_arrays, gender_age_income, mean_rt_per_cat, ratings_one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load user U0011 (not enough images): 1 total failure\n",
      "Failed to load user U0024 (bad images): 2 total failures\n",
      "Failed to load user U0039 (bad images): 3 total failures\n",
      "Failed to load user U0042 (bad images): 4 total failures\n",
      "Loaded user U0120/U0120\r"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    X0 = np.zeros((0, 10+3+num_categories+num_categories)) # B5, Gender, Age, Income, Mean Rating per Category, Ad Category\n",
    "    X1 = np.zeros((0, 5+5+1, img_width, img_height, img_channels)) # 5 Positive Images, 5 Negative Images, Ad Image\n",
    "    X2 = np.zeros((0, max_text_length, char_embedding_size)) # Ad text\n",
    "    Y = np.zeros((0, 5)) # Rating\n",
    "\n",
    "    last_user_id = user_directories[-1].replace(\"/\", \"\\\\\").split(\"\\\\\")[-1]\n",
    "    for (\n",
    "        user_id,\n",
    "        b5,\n",
    "        im_neg_arrays,\n",
    "        im_pos_arrays,\n",
    "        gender_age_income,\n",
    "        mean_rt_per_cat,\n",
    "        ratings_one_hot\n",
    "    ) in user_data_iterator(user_directories):\n",
    "        x0 = np.broadcast_to(b5, (num_ads, *b5.shape))\n",
    "        x0 = np.concatenate((x0, np.broadcast_to(gender_age_income, (num_ads, *gender_age_income.shape))), axis=1)\n",
    "        x0 = np.concatenate((x0, np.broadcast_to(mean_rt_per_cat, (num_ads, *mean_rt_per_cat.shape))), axis=1)\n",
    "        x0 = np.concatenate((x0, ad_categories), axis=1)\n",
    "\n",
    "        x1 = np.broadcast_to(im_pos_arrays, (num_ads, *im_pos_arrays.shape))\n",
    "        x1 = np.concatenate((x1, np.broadcast_to(im_neg_arrays, (num_ads, *im_neg_arrays.shape))), axis=1)\n",
    "        x1 = np.concatenate((x1, ad_imgs[:, np.newaxis, :, :, :]), axis=1)\n",
    "\n",
    "        x2 = ad_char_embeddings\n",
    "\n",
    "        y = ratings_one_hot\n",
    "\n",
    "        X0 = np.concatenate((X0, x0))\n",
    "        X1 = np.concatenate((X1, x1))\n",
    "        X2 = np.concatenate((X2, x2))\n",
    "        Y = np.concatenate((Y, y))\n",
    "\n",
    "        print(f\"Loaded user {user_id}/{last_user_id}\", end=\"\\r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    np.savez_compressed(\"data/user-data.npz\", X0=X0, X1=X1, X2=X2, Y=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.load(\"data/user-data.npz\")\n",
    "X0 = d[\"X0\"]\n",
    "X1 = d[\"X1\"]\n",
    "X2 = d[\"X2\"]\n",
    "Y = d[\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 11, 16, 16,  0           []                               \n",
      "                                 3)]                                                              \n",
      "                                                                                                  \n",
      " conv3d (Conv3D)                (None, 11, 14, 14,   112         ['input_2[0][0]']                \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " max_pooling3d (MaxPooling3D)   (None, 11, 7, 7, 4)  0           ['conv3d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv3d_1 (Conv3D)              (None, 11, 5, 5, 2)  74          ['max_pooling3d[0][0]']          \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 369, 39)]    0           []                               \n",
      "                                                                                                  \n",
      " max_pooling3d_1 (MaxPooling3D)  (None, 11, 1, 1, 2)  0          ['conv3d_1[0][0]']               \n",
      "                                                                                                  \n",
      " simple_rnn (SimpleRNN)         (None, 4)            176         ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 53)]         0           []                               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 22)           0           ['max_pooling3d_1[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 4)            0           ['simple_rnn[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 79)           0           ['input_1[0][0]',                \n",
      "                                                                  'flatten[0][0]',                \n",
      "                                                                  'flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2)            160         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 5)            15          ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def one_hots_to_ratings(one_hots):\n",
    "    return tf.reduce_sum(one_hots * tf.range(1,6,dtype=tf.dtypes.float32), axis=-1)\n",
    "\n",
    "def ratings_mae(y_true, y_pred):\n",
    "    ratings_true = one_hots_to_ratings(y_true)\n",
    "    ratings_pred = one_hots_to_ratings(y_pred)\n",
    "    return tf.reduce_mean(tf.math.abs(ratings_true-ratings_pred))\n",
    "\n",
    "def create_model():\n",
    "    input0 = Input(X0.shape[1:])\n",
    "    input1 = Input(X1.shape[1:])\n",
    "    input2 = Input(X2.shape[1:])\n",
    "\n",
    "    output1 = Conv3D(4, (1,3,3), activation=\"relu\", kernel_regularizer=\"l2\")(input1)\n",
    "    output1 = MaxPooling3D(pool_size=(1,2,2))(output1)\n",
    "    output1 = Conv3D(2, (1,3,3), activation=\"relu\", kernel_regularizer=\"l2\")(output1)\n",
    "    output1 = MaxPooling3D(pool_size=(1,4,4))(output1)\n",
    "    output1 = Flatten()(output1)\n",
    "    output2 = SimpleRNN(4)(input2)\n",
    "    output2 = Flatten()(output2)\n",
    "    output = Concatenate()([input0, output1, output2])\n",
    "    output = Dense(2, activation=\"relu\", kernel_regularizer=\"l2\")(output)\n",
    "    output = Dense(5, activation=\"softmax\", kernel_regularizer=\"l2\")(output)\n",
    "\n",
    "    return Model(inputs=[input0, input1, input2], outputs=[output])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = create_model()\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\", ratings_mae])\n",
    "    model.summary()\n",
    "    plot_model(model, to_file=\"users_model.png\", show_shapes=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    total_num = Y.shape[0]\n",
    "    batch_size = 64\n",
    "\n",
    "    train_prop = 0.8\n",
    "    train_num = int(train_prop * total_num)\n",
    "    train_split_num = np.ceil(train_num/batch_size)\n",
    "\n",
    "    # permutation = np.random.permutation(total_num)\n",
    "    permutation = np.arange(total_num)\n",
    "    X = (X0[permutation], X1[permutation], X2[permutation])\n",
    "    Y = Y[permutation]\n",
    "\n",
    "    X_train = list(np.array_split(x[:train_num], train_split_num) for x in X)\n",
    "    X_train = list(map(list, zip(*X_train)))\n",
    "\n",
    "    X_val = list(x[train_num:] for x in X)\n",
    "\n",
    "    Y_train = np.array_split(Y[:train_num], train_split_num)\n",
    "    Y_val = Y[train_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    checkpoints_dir=\"users-checkpoints\"\n",
    "    filepath = os.path.join(checkpoints_dir, \"model-{epoch:06d}-{val_ratings_mae:.4f}.hdf5\")\n",
    "    checkpoint = ModelCheckpoint(filepath, save_freq=len(X_train), save_weights_only=True, monitor=\"val_ratings_mae\", verbose=0, save_best_only=False, mode=\"min\")\n",
    "\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 435:               109/109 - 5s - loss: 1.5960 - categorical_accuracy: 0.6022 - ratings_mae: 1.0732 - 5s/epoch - 50ms/step\n",
      "Epoch 2, Step 870:               109/109 - 6s - loss: 1.4204 - categorical_accuracy: 0.6022 - ratings_mae: 0.9984 - 6s/epoch - 53ms/step\n",
      "Epoch 3, Step 1305:              109/109 - 5s - loss: 1.2912 - categorical_accuracy: 0.6022 - ratings_mae: 0.9660 - 5s/epoch - 47ms/step\n",
      "Epoch 4, Step 1740:              109/109 - 6s - loss: 1.2562 - categorical_accuracy: 0.6022 - ratings_mae: 0.9142 - 6s/epoch - 52ms/step\n",
      "Epoch 5, Step 2175:              109/109 - 5s - loss: 1.2278 - categorical_accuracy: 0.6022 - ratings_mae: 0.9873 - 5s/epoch - 46ms/step\n",
      "Epoch 6, Step 2610:              109/109 - 6s - loss: 1.1950 - categorical_accuracy: 0.6022 - ratings_mae: 0.8758 - 6s/epoch - 54ms/step\n",
      "Epoch 7, Step 3045:              109/109 - 5s - loss: 1.1774 - categorical_accuracy: 0.6022 - ratings_mae: 0.8988 - 5s/epoch - 48ms/step\n",
      "Epoch 8, Step 3480:              109/109 - 5s - loss: 1.1642 - categorical_accuracy: 0.6022 - ratings_mae: 0.8656 - 5s/epoch - 49ms/step\n",
      "Epoch 9, Step 3915:              109/109 - 5s - loss: 1.1551 - categorical_accuracy: 0.5674 - ratings_mae: 0.8592 - 5s/epoch - 44ms/step\n",
      "Epoch 10, Step 4350:             109/109 - 4s - loss: 1.1564 - categorical_accuracy: 0.5852 - ratings_mae: 0.8446 - 4s/epoch - 37ms/step\n",
      "Epoch 11, Step 4785:             109/109 - 5s - loss: 1.1474 - categorical_accuracy: 0.5710 - ratings_mae: 0.8461 - 5s/epoch - 48ms/step\n",
      "Epoch 12, Step 5220:                                   109/109 - 5s - loss: 1.1435 - categorical_accuracy: 0.5677 - ratings_mae: 0.8503 - 5s/epoch - 44ms/step\n",
      "Epoch 13, Step 5655:                                    109/109 - 8s - loss: 1.3013 - categorical_accuracy: 0.4530 - ratings_mae: 1.1064 - 8s/epoch - 75ms/step\n",
      "Epoch 14, Step 6090:                                     109/109 - 4s - loss: 1.1392 - categorical_accuracy: 0.5717 - ratings_mae: 0.8534 - 4s/epoch - 38ms/step\n",
      "Epoch 15, Step 6525:             109/109 - 4s - loss: 1.1364 - categorical_accuracy: 0.5777 - ratings_mae: 0.8476 - 4s/epoch - 39ms/step\n",
      "Epoch 16, Step 6960:             109/109 - 6s - loss: 1.1469 - categorical_accuracy: 0.5677 - ratings_mae: 0.8918 - 6s/epoch - 52ms/step\n",
      "Epoch 17, Step 7395:                                     109/109 - 6s - loss: 1.1366 - categorical_accuracy: 0.5717 - ratings_mae: 0.8574 - 6s/epoch - 53ms/step\n",
      "Epoch 18, Step 7830:             109/109 - 5s - loss: 1.1398 - categorical_accuracy: 0.5682 - ratings_mae: 0.8584 - 5s/epoch - 48ms/step\n",
      "Epoch 19, Step 8265:             109/109 - 15s - loss: 1.1390 - categorical_accuracy: 0.5885 - ratings_mae: 0.8158 - 15s/epoch - 134ms/step\n",
      "Epoch 20, Step 8700:                                                                                    109/109 - 7s - loss: 1.1351 - categorical_accuracy: 0.5835 - ratings_mae: 0.8200 - 7s/epoch - 62ms/step\n",
      "Epoch 21, Step 9135:             109/109 - 5s - loss: 1.1343 - categorical_accuracy: 0.5697 - ratings_mae: 0.8508 - 5s/epoch - 42ms/step\n",
      "Epoch 22, Step 9570:                                                           109/109 - 5s - loss: 1.1335 - categorical_accuracy: 0.5891 - ratings_mae: 0.8174 - 5s/epoch - 43ms/step\n",
      "Epoch 23, Step 10005:            109/109 - 5s - loss: 1.1413 - categorical_accuracy: 0.5672 - ratings_mae: 0.8771 - 5s/epoch - 45ms/step\n",
      "Epoch 24, Step 10440:            109/109 - 6s - loss: 1.1314 - categorical_accuracy: 0.5710 - ratings_mae: 0.8542 - 6s/epoch - 53ms/step\n",
      "Epoch 25, Step 10875:            109/109 - 4s - loss: 1.1285 - categorical_accuracy: 0.5730 - ratings_mae: 0.8471 - 4s/epoch - 40ms/step\n",
      "Epoch 26, Step 11310:            109/109 - 4s - loss: 1.1310 - categorical_accuracy: 0.5855 - ratings_mae: 0.8145 - 4s/epoch - 41ms/step\n",
      "Epoch 27, Step 11745:                                   109/109 - 10s - loss: 1.1428 - categorical_accuracy: 0.5684 - ratings_mae: 0.8842 - 10s/epoch - 89ms/step\n",
      "Epoch 28, Step 12180:                                    109/109 - 5s - loss: 1.1245 - categorical_accuracy: 0.5872 - ratings_mae: 0.8330 - 5s/epoch - 48ms/step\n",
      "Epoch 29, Step 12615:            109/109 - 5s - loss: 1.1245 - categorical_accuracy: 0.5766 - ratings_mae: 0.8471 - 5s/epoch - 46ms/step\n",
      "Epoch 30, Step 13050:                                   109/109 - 5s - loss: 1.1345 - categorical_accuracy: 0.5925 - ratings_mae: 0.8068 - 5s/epoch - 45ms/step\n",
      "Epoch 31, Step 13485:            "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    epochs = 100\n",
    "\n",
    "    if not os.path.isdir(checkpoints_dir):\n",
    "        os.makedirs(checkpoints_dir)\n",
    "\n",
    "    try:\n",
    "        for epoch in range(epochs):\n",
    "            for i, split in enumerate(np.random.permutation(len(X_train))):\n",
    "                model.fit(\n",
    "                    x=X_train[split],\n",
    "                    y=Y_train[split],\n",
    "                    batch_size=len(X_train[split][0]),\n",
    "                    initial_epoch=epoch,\n",
    "                    epochs=epoch+1,\n",
    "                    verbose=0,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[checkpoint]\n",
    "                )\n",
    "                print(f\"[{i+1}/{len(X_train)}]\", end=\"                        \\r\")\n",
    "\n",
    "            print(f\"Epoch {epoch+1}, Step {(epoch+1)*len(X_train)}: \", end=\"\")\n",
    "            model.evaluate(\n",
    "                x=X_val,\n",
    "                y=Y_val,\n",
    "                batch_size=batch_size,\n",
    "                verbose=2,\n",
    "                callbacks=[tensorboard_callback]\n",
    "            )\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    finally:\n",
    "        plt.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe9152bf2f574327d6e225fe0caf6c004889fb08c66ba1e27720217847b14197"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
